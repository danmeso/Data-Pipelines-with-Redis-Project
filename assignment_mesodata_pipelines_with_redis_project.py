# -*- coding: utf-8 -*-
"""ASSIGNMENT MESOData Pipelines with Redis Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NC2cDhJVXqd8lqIQcPxvAsl7GXjq14Bn

# **Data Pipelines with Redis**

**Background Information**

As a telecommunications data engineer, you have been tasked with building a pipeline that can
efficiently extract, transform, and load data from CSV files into a Postgres database. The data to
be extracted is related to customer call logs, which contain information about the duration, cost,
and destination of customer calls. The extracted data needs to be transformed to ensure it is in
the correct format and structure for storage in the database. The pipeline should also cache
data using Redis to speed up the data extraction and transformation.
"""

pip install redis

from google.colab import files

# import libraries


import pandas as pd
import psycopg2
import redis

uploaded = files.upload()

# Redis Cloud Instance Information
redis_host = 'redis-13184.c299.asia-northeast1-1.gce.cloud.redislabs.com'
redis_port ='13184'
redis_password ='xRO9HbKxtkpD3sGDniKIApicG4TYyhNW'

# Define Postgres connection details
pg_host = "105.198.57.213"
pg_database = "customer_data"
pg_user = "postgres"
pg_password = "Busaz"

# Redis Client Object
redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password)

def extract_data():
    # Extract data from CSV file using pandas
    data = pd.read_csv('customer_call_logs.csv')
    
    # Cache data in Redis for faster retrieval
    redis_client.set('customer_call_logs', data.to_json())

def transform_data():
    # Retrieve data from Redis cache
    data = pd.read_json(redis_client.get('customer_call_logs').decode('utf-8'))
   
    transformed_data = pd.DataFrame({ 'customer_id': data['customer_id'], 'call_cost_usd': data['call_cost'].str.strip('$'),  'call_destination': data['call_destination'],
        'call_date': pd.to_datetime(data['call_date']),   'call_duration_min': pd.to_timedelta(data['call_duration']).astype('timedelta64[m]') })
    return(transformed_data)

def load_data(transformed_data):
    # Connect to Postgres database
    conn = psycopg2.connect(host=pg_host,  port=5432, database=pg_database, user=pg_user, password=pg_password)

    # Create a cursor object
    cur = conn.cursor()

def main():
    """
    Main function that executes the data pipeline.
    """
    extract_data()
    transformed_data = transform_data(transformed_data)
    load_data(transformed_data)

if __name__ == '__main__':
    main()

"""# **Best practices used during the implementation**

1. Using Redis data structures

2. Ensuring reliability and fault tolerance

3. Monitoring and logging

4. Testing and debugging

# **Recommendations for deployment and running the pipeline with a cloud-based provider **

Enable Authentication

Enable Authentication

Enable Access Control
"""